{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QA User Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-13 14:45:07.622747: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA Function v.1 - initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Take in user question\n",
    "    posed_question = input('Question:')\n",
    "    \n",
    "    # Load data frame\n",
    "    df_QA = pd.read_csv('/Users/kellyshreeve/Desktop/Data-Sets/Externship/qa_merged_clean.csv')\n",
    "    \n",
    "    # Load question embeddings\n",
    "    file = open('/Users/kellyshreeve/desktop/embeddings', 'rb')\n",
    "    ques_embeddings = pickle.load(file)\n",
    "    \n",
    "    # Initiate Sentence Model\n",
    "    sent_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    # Get new question embeddings\n",
    "    new_question_embeddings = sent_model.encode(posed_question)\n",
    "\n",
    "    # Find most similar question index\n",
    "    similarity_scores = cosine_similarity([new_question_embeddings],\n",
    "                                       ques_embeddings)\n",
    "\n",
    "    best_index = np.argmax(similarity_scores)\n",
    "    \n",
    "    # Extract similar question and answer text from df\n",
    "    best_question = df_QA.loc[best_index, 'body_with_sentences_q']\n",
    "    best_answer = df_QA.loc[best_index, 'body_with_sentences_a']\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    computation_time = end_time - start_time\n",
    "    \n",
    "    # Print results\n",
    "    print(f'Posed Question: {posed_question}')\n",
    "    print(f'Similar Question: {best_question}')\n",
    "    print(f'Similar Answer: {best_answer}')\n",
    "    print(f'Embeddings Shape: {ques_embeddings.shape}')\n",
    "    print(f'Computation Time: {computation_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m question_answer()\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mquestion_answer\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m posed_question \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mQuestion:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Load data frame\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df_QA \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/Users/kellyshreeve/Desktop/Data-Sets/Externship/qa_merged_clean.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Load question embeddings\u001b[39;00m\n\u001b[1;32m     11\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/Users/kellyshreeve/desktop/embeddings\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m         nrows\n\u001b[1;32m   1706\u001b[0m     )\n\u001b[1;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1036\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1090\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1165\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1335\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[39m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[39m#  here too.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[39m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[39m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m   1331\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1332\u001b[0m     )\n\u001b[0;32m-> 1335\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   1336\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[39m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(arr_or_dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question_answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA Function v.2 - faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull data, embedding, and model load out of function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compuation Time: 45.44052767753601\n"
     ]
    }
   ],
   "source": [
    "# Load all data and sentence model\n",
    "start = time.time()\n",
    "\n",
    "# Load data frame\n",
    "df_QA = pd.read_csv('/Users/kellyshreeve/Desktop/Data-Sets/Externship/qa_merged_clean.csv')\n",
    "    \n",
    "# Load question embeddings\n",
    "file = open('/Users/kellyshreeve/desktop/ques_embeddings', 'rb')\n",
    "ques_embeddings = pickle.load(file)\n",
    "\n",
    "# Initiate Sentence Model\n",
    "sent_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Compuation Time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get user input and embeddings and return\n",
    "# similar Q/A. Does not load data or embeddings.\n",
    "\n",
    "def question_answer_v2():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Take in user question\n",
    "    posed_question = input('Question:')\n",
    "\n",
    "    # Get new question embeddings\n",
    "    new_question_embeddings = sent_model.encode(posed_question)\n",
    "\n",
    "    # Find most similar question index\n",
    "    similarity_scores = cosine_similarity([new_question_embeddings],\n",
    "                                       ques_embeddings)\n",
    "\n",
    "    best_index = np.argmax(similarity_scores)\n",
    "    \n",
    "    # Extract similar question and answer text from df\n",
    "    best_question = df_QA.loc[best_index, 'body_with_sentences_q']\n",
    "    best_answer = df_QA.loc[best_index, 'body_with_sentences_a']\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    computation_time = end_time - start_time\n",
    "    \n",
    "    # Print results\n",
    "    print(f'Posed Question: {posed_question}')\n",
    "    print()\n",
    "    print(f'Similar Question: {best_question}')\n",
    "    print()\n",
    "    print(f'Similar Answer: {best_answer}')\n",
    "    print()\n",
    "    print(f'Embeddings Shape: {ques_embeddings.shape}')\n",
    "    print()\n",
    "    print(f'Computation Time: {computation_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posed Question: What is django?\n",
      "\n",
      "Similar Question: how do i go about specifying and using an enum in a django model\n",
      "\n",
      "Similar Answer: from the https docs.djangoproject.com en dev ref models fields django.db.models.field.choices rel nofollow django documentation maybechoice 'y' 'yes' 'n' 'no' 'u' 'unknown' and you define a charfield in your model married models.charfield max_len h choices maybechoice you can do the same with integer fields if you don't like to have letters in your db. in that case rewrite your choices maybechoice 'yes' 'no' 'unknown'\n",
      "\n",
      "Embeddings Shape: (10001, 768)\n",
      "\n",
      "Computation Time: 4.076124906539917\n"
     ]
    }
   ],
   "source": [
    "question_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posed Question: How to add a column in Pandas?\n",
      "\n",
      "Similar Question: how do you change the size of figure drawn with matplotlib\n",
      "\n",
      "Similar Answer: the following seems to work from pylab import rcparams rcparams['figure.figsize'] this makes the figure's width inches and its height b inches b . the figure class then uses this as the default value for one of its arguments.\n",
      "\n",
      "Embeddings Shape: (10001, 768)\n",
      "\n",
      "Computation Time: 12.959703922271729\n"
     ]
    }
   ],
   "source": [
    "question_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posed Question: How to find a full path to a font?\n",
      "\n",
      "Similar Question: does anyone know how to do this i need to add a header of the form value value\n",
      "\n",
      "Similar Answer: as the question is phrased it's hard to guess what the intention or even the intended semantics is. for setting headers try the following import soappy headers soappy.types.headertype headers.value value or [...] headers.foo value headers.bar value\n",
      "\n",
      "Embeddings Shape: (10001, 768)\n",
      "\n",
      "Computation Time: 7.04338002204895\n"
     ]
    }
   ],
   "source": [
    "question_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posed Question: How to find a full path to a font in photoshop javascript?\n",
      "\n",
      "Similar Question: is there any python module for rendering a html page with javascript and get back a dom object i want to parse a page which generates almost all of its content using javascript.\n",
      "\n",
      "Similar Answer: only way i know to accomplish this would be to drive real browser for example using http selenium rc.openqa.org rel nofollow selenium rc .\n",
      "\n",
      "Embeddings Shape: (10001, 768)\n",
      "\n",
      "Computation Time: 14.047891855239868\n"
     ]
    }
   ],
   "source": [
    "question_answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA Function v.3 - normalize question text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compuation Time: 42.505502223968506\n"
     ]
    }
   ],
   "source": [
    "# Load all data and sentence model\n",
    "start = time.time()\n",
    "\n",
    "# Load data frame\n",
    "df_QA = pd.read_csv('/Users/kellyshreeve/Desktop/Data-Sets/Externship/qa_merged_clean.csv')\n",
    "    \n",
    "# Load question embeddings\n",
    "file = open('/Users/kellyshreeve/desktop/ques_embeddings', 'rb')\n",
    "ques_embeddings = pickle.load(file)\n",
    "\n",
    "# Initiate Sentence Model\n",
    "sent_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Compuation Time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_with_sentences(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('<p>', ' ')\n",
    "    text = text.replace('</p>', ' ')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('<a', ' ')\n",
    "    text = text.replace('</a>', ' ')\n",
    "    text = text.replace('href=', ' ')\n",
    "    text = text.replace('</code', ' ')\n",
    "    text = text.replace('</pre>', ' ')\n",
    "    text = text.replace('<code>', ' ')\n",
    "    text = text.replace('jpeg', ' ')\n",
    "    text = text.replace('jpg', ' ')\n",
    "    text = text.replace('pre', ' ')\n",
    "    text = text.replace('pdf', ' ')\n",
    "    text = text.replace('gt', ' ')\n",
    "    text = re.sub(r\"[^a-zA-z'.]\", ' ', text)\n",
    "    text = text.split()\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get user input and embeddings and return\n",
    "# similar Q/A. Does not load data or embeddings.\n",
    "# Normalizes question text\n",
    "\n",
    "def question_answer_v3():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Take in user question\n",
    "    posed_question = input('Question:')\n",
    "    \n",
    "    # Normalize question\n",
    "    posed_quesiton = normalize_with_sentences(posed_question)\n",
    "\n",
    "    # Get new question embeddings\n",
    "    new_question_embeddings = sent_model.encode(posed_question)\n",
    "\n",
    "    # Find most similar question index\n",
    "    similarity_scores = cosine_similarity([new_question_embeddings],\n",
    "                                       ques_embeddings)\n",
    "\n",
    "    best_index = np.argmax(similarity_scores)\n",
    "    \n",
    "    # Extract similar question and answer text from df\n",
    "    best_question = df_QA.loc[best_index, 'body_with_sentences_q']\n",
    "    best_answer = df_QA.loc[best_index, 'body_with_sentences_a']\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    computation_time = end_time - start_time\n",
    "    \n",
    "    # Print results\n",
    "    print(f'Posed Question: {posed_question}')\n",
    "    print()\n",
    "    print(f'Similar Question: {best_question}')\n",
    "    print()\n",
    "    print(f'Similar Answer: {best_answer}')\n",
    "    print()\n",
    "    print(f'Embeddings Shape: {ques_embeddings.shape}')\n",
    "    print()\n",
    "    print(f'Computation Time: {computation_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posed Question: What is python?\n",
      "\n",
      "Similar Question: how do you create a weak reference to an object in python\n",
      "\n",
      "Similar Answer: import weakref class object ... pass ... o object r weakref.ref o if the reference is still active r will be o otherwise none do_something_with_o r see the http docs.python.org lib module weakref.html wearkref module docs for more details. you can also use weakref.proxy to create an object that proxies o. will throw referenceerror if used when the referent is no longer referenced.\n",
      "\n",
      "Embeddings Shape: (10001, 768)\n",
      "\n",
      "Computation Time: 5.623437166213989\n"
     ]
    }
   ],
   "source": [
    "question_answer_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posed Question: What is pandas?\n",
      "\n",
      "Similar Question: how do i turn a python program into an .egg file\n",
      "\n",
      "Similar Answer: http peak.telecommunity.com devcenter setuptools setuptools is the software that creates http peak.telecommunity.com devcenter pythoneggs .egg files . it's an extension of the http docs.python.org lib module distutils.html distutils package in the standard library. the process involves creating a setup.py file then python setup.py bdist_egg creates an .egg package.\n",
      "\n",
      "Embeddings Shape: (10001, 768)\n",
      "\n",
      "Computation Time: 9.889105796813965\n"
     ]
    }
   ],
   "source": [
    "question_answer_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posed Question: What is Django?\n",
      "\n",
      "Similar Question: how do i go about specifying and using an enum in a django model\n",
      "\n",
      "Similar Answer: from the https docs.djangoproject.com en dev ref models fields django.db.models.field.choices rel nofollow django documentation maybechoice 'y' 'yes' 'n' 'no' 'u' 'unknown' and you define a charfield in your model married models.charfield max_len h choices maybechoice you can do the same with integer fields if you don't like to have letters in your db. in that case rewrite your choices maybechoice 'yes' 'no' 'unknown'\n",
      "\n",
      "Embeddings Shape: (10001, 768)\n",
      "\n",
      "Computation Time: 8.851870059967041\n"
     ]
    }
   ],
   "source": [
    "question_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posed Question: How to find the full path to a font?\n",
      "\n",
      "Similar Question: does anyone know how to do this i need to add a header of the form value value\n",
      "\n",
      "Similar Answer: as the question is phrased it's hard to guess what the intention or even the intended semantics is. for setting headers try the following import soappy headers soappy.types.headertype headers.value value or [...] headers.foo value headers.bar value\n",
      "\n",
      "Embeddings Shape: (10001, 768)\n",
      "\n",
      "Computation Time: 8.934815883636475\n"
     ]
    }
   ],
   "source": [
    "question_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 0 3 1 5 4 2 7]\n",
      "[ 7 10  9 11]\n",
      "[7, 9, 10, 11]\n",
      "[6 0 3 1 5]\n"
     ]
    }
   ],
   "source": [
    "# Find top 5\n",
    "x = np.array([2, 5, 9, 3, 10, 7, 2, 11])\n",
    "\n",
    "# Top 4\n",
    "print(np.argpartition(x, -4))\n",
    "print(x[np.argpartition(x, -4)][-4:])\n",
    "\n",
    "# Sorted Top 4\n",
    "print(sorted(x[np.argpartition(x, -4)][-4:]))\n",
    "\n",
    "# Smallest 5\n",
    "print(np.argpartition(x, 5)[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
