{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question Answer Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Packages and Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_QA = pd.read_csv('/Users/kellyshreeve/Desktop/Data-Sets/Externship/qa_merged_clean.csv',\n",
    "                    parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 987122 entries, 0 to 987121\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Unnamed: 0             987122 non-null  int64  \n",
      " 1   id_q                   987122 non-null  int64  \n",
      " 2   owner_user_id_q        973748 non-null  float64\n",
      " 3   creation_date_q        987122 non-null  object \n",
      " 4   score_q                987122 non-null  int64  \n",
      " 5   title                  987122 non-null  object \n",
      " 6   body_q                 987122 non-null  object \n",
      " 7   body_normalized_q      987120 non-null  object \n",
      " 8   title_normalized       987122 non-null  object \n",
      " 9   body_with_sentences_q  987122 non-null  object \n",
      " 10  title_with_sentences   987122 non-null  object \n",
      " 11  creation_year_q        987122 non-null  int64  \n",
      " 12  id_a                   987122 non-null  float64\n",
      " 13  owner_user_id_a        981755 non-null  float64\n",
      " 14  creation_date_a        987122 non-null  object \n",
      " 15  parent_id              987122 non-null  float64\n",
      " 16  score_a                987122 non-null  float64\n",
      " 17  body_a                 987122 non-null  object \n",
      " 18  body_normalized_a      987115 non-null  object \n",
      " 19  body_with_sentences_a  987117 non-null  object \n",
      " 20  creation_year_a        987122 non-null  float64\n",
      " 21  answer_length          987122 non-null  int64  \n",
      " 22  question_length        987122 non-null  int64  \n",
      "dtypes: float64(6), int64(6), object(11)\n",
      "memory usage: 173.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_QA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                   0\n",
      "id_q                         0\n",
      "owner_user_id_q          13374\n",
      "creation_date_q              0\n",
      "score_q                      0\n",
      "title                        0\n",
      "body_q                       0\n",
      "body_normalized_q            2\n",
      "title_normalized             0\n",
      "body_with_sentences_q        0\n",
      "title_with_sentences         0\n",
      "creation_year_q              0\n",
      "id_a                         0\n",
      "owner_user_id_a           5367\n",
      "creation_date_a              0\n",
      "parent_id                    0\n",
      "score_a                      0\n",
      "body_a                       0\n",
      "body_normalized_a            7\n",
      "body_with_sentences_a        5\n",
      "creation_year_a              0\n",
      "answer_length                0\n",
      "question_length              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_QA.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_QA=df_QA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **QA Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset data for questions with answers and scores above 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Score Descriptives\n",
      "count    913099.000000\n",
      "mean          3.239337\n",
      "std          22.090040\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           1.000000\n",
      "75%           3.000000\n",
      "max        8384.000000\n",
      "Name: score_a, dtype: float64\n",
      "\n",
      "Question Score Descriptives\n",
      "count    913099.000000\n",
      "mean          7.769584\n",
      "std          65.424836\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           1.000000\n",
      "75%           3.000000\n",
      "max        5524.000000\n",
      "Name: score_q, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Subset for Q & A with positive scores\n",
    "df_QA = df_QA[(df_QA['score_a'] >= 0) & (df_QA['score_q'] >= 0)]\n",
    "\n",
    "print('Answer Score Descriptives')\n",
    "print(df_QA['score_a'].describe())\n",
    "print()\n",
    "print('Question Score Descriptives')\n",
    "print(df_QA['score_q'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All question and answer scores now have a minimum of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 913,099 remaining Q/A pairs where both question and answer have scores > 0 and every question has at least one answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with specific answer as context\n",
    "result: got an answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                              10\n",
       "id_q                                                                   535\n",
       "owner_user_id_q                                                      154.0\n",
       "creation_date_q                                  2008-08-02 18:43:54+00:00\n",
       "score_q                                                                 40\n",
       "title                    Continuous Integration System for a Python Cod...\n",
       "body_q                   <p>I'm starting work on a hobby project with a...\n",
       "body_normalized_q        i'm starting work on a hobby project with a py...\n",
       "title_normalized         continuous integration system for a python cod...\n",
       "body_with_sentences_q    i'm starting work on a hobby project with a py...\n",
       "title_with_sentences     continuous integration system for a python cod...\n",
       "creation_year_q                                                       2008\n",
       "id_a                                                               61746.0\n",
       "owner_user_id_a                                                     6372.0\n",
       "creation_date_a                                  2008-09-15 00:11:21+00:00\n",
       "parent_id                                                            535.0\n",
       "score_a                                                               13.0\n",
       "body_a                   <p>We use both Buildbot and Hudson for Jython ...\n",
       "body_normalized_a        we use both buildbot and hudson for jython dev...\n",
       "body_with_sentences_a    we use both buildbot and hudson for jython dev...\n",
       "creation_year_a                                                     2008.0\n",
       "answer_length                                                          217\n",
       "question_length                                                        109\n",
       "Name: 10, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose row 10\n",
    "display(df_QA.loc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a relevant question for row 10\n",
    "question = 'how to do hobby project?'\n",
    "answer_text = df_QA.loc[10, 'body_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: build it yourself\n",
      "Computation Time: 4.39 seconds\n"
     ]
    }
   ],
   "source": [
    "# BERT QA with row 10\n",
    "start_time = time.time()\n",
    "\n",
    "input_ids = bert_tokenizer.encode(question, answer_text)\n",
    "\n",
    "attention_mask = [1] * len(input_ids)\n",
    "\n",
    "output = bert_model(torch.tensor([input_ids]), attention_mask=torch.tensor([attention_mask]))\n",
    "\n",
    "start_index = torch.argmax(output[0][0, :len(input_ids) - input_ids.index(bert_tokenizer.sep_token_id)])\n",
    "end_index = torch.argmax(output[1][0, :len(input_ids) - input_ids.index(bert_tokenizer.sep_token_id)])\n",
    "\n",
    "answer = bert_tokenizer.decode(input_ids[start_index:end_index + 1], skip_special_tokens=True)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "computation_time = end_time - start_time\n",
    "\n",
    "print(f'Answer: {answer}')\n",
    "print(f'Computation Time: {computation_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find similar questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get embedding for first 10,000 Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_QA = df_QA.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Embeddings Shape: (10001, 768)\n",
      "Computation Time: 1181.21 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get embeddings for data set questions\n",
    "start_time = time.time()\n",
    "\n",
    "questions = df_QA.loc[0:10000, 'body_with_sentences_q']\n",
    "\n",
    "sent_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "ques_embeddings = sent_model.encode(questions)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "computation_time = end_time - start_time\n",
    "\n",
    "print(f'Question Embeddings Shape: {ques_embeddings.shape}')\n",
    "print(f'Computation Time: {computation_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/kellyshreeve/Desktop/ques_embeddings', 'wb') as file:\n",
    "    pickle.dump(ques_embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/Users/kellyshreeve/desktop/ques_embeddings', 'rb')\n",
    "pickled_embeddings = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find similar questions with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "\n",
      "so when playing with the development i can just set settings.debug to true and if an error occures i can see it nicely formatted with good stack trace and request information. but on kind of production site i'd rather use debug false and show visitors some standard error page with information that i'm working on fixing this bug at this moment br at the same time i'd like to have some way of logging all those information stack trace and request info to a file on my server so i can just output it to my console and watch errors scroll email the log to me every hour or something like this. what logging solutions would you recomend for a django site that would meet those simple requirements i have the application running as fcgi server and i'm using apache web server as frontend although thinking of going to lighttpd .\n",
      "\n",
      "Answer:\n",
      "\n",
      "well when debug false django will automatically mail a full traceback of any error to each person listed in the admins setting which gets you notifications tty much for free. if you'd like more fine grained control you can write and add to your settings a middleware class which defines a method named process_exception which will have access to the exception that was raised http docs.djangoproject.com en dev topics http middleware process exception http docs.djangoproject.com en dev topics http middleware process exception your process_exception method can then perform whatever type of logging you'd like writing to console writing to a file etc. etc. edit though it's a bit less useful you can also listen for the got_request_exception signal which will be sent whenever an exception is encountered during request processing http docs.djangoproject.com en dev ref signals got request exception http docs.djangoproject.com en dev ref signals got request exception this does em not em give you access to the exception object however so the middleware method is much easier to work with.\n",
      "\n",
      "Best Index: 5822\n",
      "\n",
      "Computation Time: 1.02 seconds\n"
     ]
    }
   ],
   "source": [
    "# Use cosine distance to find similar questions\n",
    "start_time = time.time()\n",
    "\n",
    "new_question = 'What is pandas?'\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "new_question_embeddings = model.encode(new_question)\n",
    "\n",
    "similarity_scores = cosine_similarity([new_question_embeddings],\n",
    "                                       ques_embeddings)\n",
    "\n",
    "best_index = np.argmin(similarity_scores)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "computation_time = end_time - start_time\n",
    "\n",
    "best_question = df_QA.loc[best_index, 'body_with_sentences_q']\n",
    "best_answer = df_QA.loc[best_index, 'body_with_sentences_a']\n",
    "\n",
    "print('Question Posed:')\n",
    "print(new_question)\n",
    "print()\n",
    "print('Question:')\n",
    "print()\n",
    "print(best_question)\n",
    "print()\n",
    "print('Answer:')\n",
    "print()\n",
    "print(best_answer)\n",
    "print()\n",
    "print(f'Best Index: {best_index}')\n",
    "print()\n",
    "print(f'Computation Time: {computation_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find answer to question from answer to similar question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "\n",
      "Computation Time: 1.97 seconds\n"
     ]
    }
   ],
   "source": [
    "# Find answer from most relevant question\n",
    "start_time = time.time()\n",
    "\n",
    "new_question = 'What is pandas?'\n",
    "\n",
    "input_ids = bert_tokenizer.encode(new_question, df_QA.loc[5822, 'body_a'])\n",
    "\n",
    "attention_mask = [1] * len(input_ids)\n",
    "\n",
    "output = bert_model(torch.tensor([input_ids]), attention_mask=torch.tensor([attention_mask]))\n",
    "\n",
    "start_index = torch.argmax(output[0][0, :len(input_ids) - input_ids.index(bert_tokenizer.sep_token_id)])\n",
    "end_index = torch.argmax(output[1][0, :len(input_ids) - input_ids.index(bert_tokenizer.sep_token_id)])\n",
    "\n",
    "answer = bert_tokenizer.decode(input_ids[start_index:end_index + 1], skip_special_tokens=True)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "computation_time = end_time - start_time\n",
    "\n",
    "print(f'Question: {new_question}')\n",
    "print()\n",
    "print(f'Answer: {answer}')\n",
    "print()\n",
    "print(f'Computation Time: {computation_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT did not find an answer in the given answer text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that BERT QA works for a more relevant question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: django will automatically mail a full traceback of any error to each person listed in the < code > admins < / code > setting\n",
      "\n",
      "Computation Time: 2.19 seconds\n"
     ]
    }
   ],
   "source": [
    "# Find an answer from a more relevant question\n",
    "start_time = time.time()\n",
    "\n",
    "relevant_question = 'How to use django?'\n",
    "\n",
    "input_ids = bert_tokenizer.encode(relevant_question, df_QA.loc[5822, 'body_a'])\n",
    "\n",
    "attention_mask = [1] * len(input_ids)\n",
    "\n",
    "output = bert_model(torch.tensor([input_ids]), attention_mask=torch.tensor([attention_mask]))\n",
    "\n",
    "start_index = torch.argmax(output[0][0, :len(input_ids) - input_ids.index(bert_tokenizer.sep_token_id)])\n",
    "end_index = torch.argmax(output[1][0, :len(input_ids) - input_ids.index(bert_tokenizer.sep_token_id)])\n",
    "\n",
    "answer = bert_tokenizer.decode(input_ids[start_index:end_index + 1], skip_special_tokens=True)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "computation_time = end_time - start_time\n",
    "\n",
    "print(f'Question: {relevant_question}')\n",
    "print(f'Answer: {answer}')\n",
    "print()\n",
    "print(f'Computation Time: {computation_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not a great answer, BERT did find an answer in the answer text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar question function\n",
    "def find_similar_question(question, df, question_column):\n",
    "    new_question_embeddings = model.encode(new_question)\n",
    "\n",
    "    similarity_scores = cosine_similarity([new_question_embeddings],\n",
    "                                        ques_embeddings)\n",
    "\n",
    "    best_index = np.argmin(similarity_scores)\n",
    "\n",
    "    print(f'Posed Question: {question}')\n",
    "    print(f'Most Similar Question: {df.loc[best_index, question_column]})\n",
    "\n",
    "# Try new questions\n",
    "find_similar_question('What is python?', df_QA, 'body_with_sentences_q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find similar answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get embeddings for first 10,000 answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Embeddings Shape: (10001, 768)\n",
      "Computation Time: 1125.99 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get embeddings for data set answers\n",
    "start_time = time.time()\n",
    "\n",
    "sentence_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "answers = df_QA.loc[0:10000, 'body_with_sentences_a']\n",
    "\n",
    "answer_embeddings = sentence_model.encode(answers)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "computation_time = end_time - start_time\n",
    "\n",
    "print(f'Question Embeddings Shape: {ques_embeddings.shape}')\n",
    "print(f'Computation Time: {computation_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find answers similar to question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question Posed:\n",
      "\n",
      "What is pandas?\n",
      "\n",
      "Question:\n",
      "\n",
      "i recently discovered the notify extension in mercurial which allows me quickly send out emails whenever i push changes but i'm tty sure i'm still missing out on a lot of functionality which could make my life a lot easier. ul li notify extension http www.selenic.com mercurial wiki index.cgi notifyextension rel nofollow http www.selenic.com mercurial wiki index.cgi notifyextension li ul which mercurial hook or combination of interoperating hooks is the most useful for working in a loosely connected team please add links to non standard parts you use and or add the hook or a description how to set it up so others can easily use it.\n",
      "\n",
      "Answer:\n",
      "\n",
      "i really enjoy what i did with my custom hook. i have it post a message to my campfire account campfire is a group based app . it worked out really well. because i had my clients in there and it could show him my progress.\n",
      "\n",
      "Best Index: 1419\n",
      "\n",
      "Computation Time: 1.18 seconds\n"
     ]
    }
   ],
   "source": [
    "# Use cosine distance to find answer similar to question\n",
    "start_time = time.time()\n",
    "\n",
    "new_question = 'What is pandas?'\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "new_question_embeddings = sentence_model.encode(new_question)\n",
    "\n",
    "similarity_scores = cosine_similarity([new_question_embeddings],\n",
    "                                       answer_embeddings)\n",
    "\n",
    "best_index = np.argmin(similarity_scores)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "computation_time = end_time - start_time\n",
    "\n",
    "best_question = df_QA.loc[best_index, 'body_with_sentences_q']\n",
    "best_answer = df_QA.loc[best_index, 'body_with_sentences_a']\n",
    "\n",
    "print('Question Posed:')\n",
    "print()\n",
    "print(new_question)\n",
    "print()\n",
    "print('Question:')\n",
    "print()\n",
    "print(best_question)\n",
    "print()\n",
    "print('Answer:')\n",
    "print()\n",
    "print(best_answer)\n",
    "print()\n",
    "print(f'Best Index: {best_index}')\n",
    "print()\n",
    "print(f'Computation Time: {computation_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also not a relevant answer. Difficult to know if it would work better with more embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to request access at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf and pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    262\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:429\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    430\u001b[0m         path_or_repo_id,\n\u001b[1;32m    431\u001b[0m         filename,\n\u001b[1;32m    432\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    433\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    434\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    435\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    436\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    437\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    438\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    439\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    440\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    441\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1346\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1345\u001b[0m     \u001b[39m# Repo not found => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1346\u001b[0m     \u001b[39mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1347\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[39m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1232\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1232\u001b[0m     metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1233\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1234\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1235\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1236\u001b[0m         timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   1237\u001b[0m     )\n\u001b[1;32m   1238\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[1;32m   1239\u001b[0m     \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1608\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1599\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1600\u001b[0m     method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1601\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1606\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m   1607\u001b[0m )\n\u001b[0;32m-> 1608\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1610\u001b[0m \u001b[39m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:277\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    274\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[1;32m    275\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot access gated repo for url \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     )\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mraise\u001b[39;00m GatedRepoError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39melif\u001b[39;00m error_code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRepoNotFound\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m401\u001b[39m:\n\u001b[1;32m    280\u001b[0m     \u001b[39m# 401 is misleading as it is returned for:\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[39m#    - private and gated repos if user is not authenticated\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[39m#    - missing repos\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[39m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[39m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-651b2813-1ef0dee056b6568216ea62a9;8defc2d1-1259-4d8d-8d42-5e91d63717fa)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/tokenizer_config.json.\nRepo model meta-llama/Llama-2-7b-chat-hf is gated. You must be authenticated to access it.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llama_tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mmeta-llama/Llama-2-7b-chat-hf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m pipeline \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39mpipeline(\n\u001b[1;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtext-generation\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16,\n\u001b[1;32m      7\u001b[0m     device_map\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      8\u001b[0m ) \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:686\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    685\u001b[0m \u001b[39m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m tokenizer_config \u001b[39m=\u001b[39m get_tokenizer_config(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    687\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    688\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tokenizer_config[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:519\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     token \u001b[39m=\u001b[39m use_auth_token\n\u001b[1;32m    518\u001b[0m commit_hash \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 519\u001b[0m resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    520\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m    521\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[1;32m    522\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    523\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    524\u001b[0m     resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    525\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    526\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    527\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    528\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    529\u001b[0m     subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    530\u001b[0m     _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    531\u001b[0m     _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    532\u001b[0m     _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    533\u001b[0m )\n\u001b[1;32m    534\u001b[0m \u001b[39mif\u001b[39;00m resolved_config_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    535\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:444\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    430\u001b[0m         path_or_repo_id,\n\u001b[1;32m    431\u001b[0m         filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m         local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    445\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to access a gated repo.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMake sure to request access at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m and pass a token having permission to this repo either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    450\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`token=<your_token>`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    455\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to request access at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf and pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`."
     ]
    }
   ],
   "source": [
    "llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    'text-generation',\n",
    "    model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models_hf/7B'. Use `repo_type` argument if needed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llama_model \u001b[39m=\u001b[39m LlamaForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39m./models_hf/7B\u001b[39;49m\u001b[39m\"\u001b[39;49m, load_in_8bit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, device_map\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m'\u001b[39;49m, torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:2389\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2386\u001b[0m \u001b[39mif\u001b[39;00m commit_hash \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2387\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2388\u001b[0m         \u001b[39m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 2389\u001b[0m         resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m   2390\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   2391\u001b[0m             CONFIG_NAME,\n\u001b[1;32m   2392\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2393\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   2394\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   2395\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   2396\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   2397\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2398\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2399\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   2400\u001b[0m             _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   2401\u001b[0m             _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   2402\u001b[0m         )\n\u001b[1;32m   2403\u001b[0m         commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   2404\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:429\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    427\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    430\u001b[0m         path_or_repo_id,\n\u001b[1;32m    431\u001b[0m         filename,\n\u001b[1;32m    432\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    433\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    434\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    435\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    436\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    437\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    438\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    439\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    440\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    441\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    445\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to access a gated repo.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMake sure to request access at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m and pass a token having permission to this repo either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mfor\u001b[39;00m arg_name, arg_value \u001b[39min\u001b[39;00m chain(\n\u001b[1;32m    106\u001b[0m     \u001b[39mzip\u001b[39m(signature\u001b[39m.\u001b[39mparameters, args),  \u001b[39m# Args values\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     kwargs\u001b[39m.\u001b[39mitems(),  \u001b[39m# Kwargs values\u001b[39;00m\n\u001b[1;32m    108\u001b[0m ):\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m    112\u001b[0m     \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         has_token \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRepo id must be a string, not \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(repo_id)\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n\u001b[1;32m    164\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    165\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must use alphanumeric chars or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m forbidden, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m cannot start or end the name, max length is 96:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models_hf/7B'. Use `repo_type` argument if needed."
     ]
    }
   ],
   "source": [
    "llama_model = LlamaForCausalLM.from_pretrained(\"./models_hf/7B\", load_in_8bit=True, device_map='auto', torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models_hf/7B'. Use `repo_type` argument if needed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llama_tokenizer \u001b[39m=\u001b[39m LlamaTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39m./models_hf/7B\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1813\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1811\u001b[0m             resolved_vocab_files[file_id] \u001b[39m=\u001b[39m download_url(file_path, proxies\u001b[39m=\u001b[39mproxies)\n\u001b[1;32m   1812\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1813\u001b[0m         resolved_vocab_files[file_id] \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m   1814\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   1815\u001b[0m             file_path,\n\u001b[1;32m   1816\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1817\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1818\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1819\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1820\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1821\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1822\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1823\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1824\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   1825\u001b[0m             _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1826\u001b[0m             _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1827\u001b[0m             _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   1828\u001b[0m         )\n\u001b[1;32m   1829\u001b[0m         commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_vocab_files[file_id], commit_hash)\n\u001b[1;32m   1831\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unresolved_files) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/utils/hub.py:429\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    427\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    430\u001b[0m         path_or_repo_id,\n\u001b[1;32m    431\u001b[0m         filename,\n\u001b[1;32m    432\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    433\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    434\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    435\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    436\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    437\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    438\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    439\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    440\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    441\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    445\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to access a gated repo.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMake sure to request access at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m and pass a token having permission to this repo either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mfor\u001b[39;00m arg_name, arg_value \u001b[39min\u001b[39;00m chain(\n\u001b[1;32m    106\u001b[0m     \u001b[39mzip\u001b[39m(signature\u001b[39m.\u001b[39mparameters, args),  \u001b[39m# Args values\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     kwargs\u001b[39m.\u001b[39mitems(),  \u001b[39m# Kwargs values\u001b[39;00m\n\u001b[1;32m    108\u001b[0m ):\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m    112\u001b[0m     \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         has_token \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRepo id must be a string, not \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(repo_id)\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n\u001b[1;32m    164\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    165\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must use alphanumeric chars or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m forbidden, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m cannot start or end the name, max length is 96:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models_hf/7B'. Use `repo_type` argument if needed."
     ]
    }
   ],
   "source": [
    "llama_tokenizer = LlamaTokenizer.from_pretrained(\"./models_hf/7B\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
